# ğŸ¾ OpenClaw Companion

Your AI, alive. Talk to an animated Live2D avatar through voice or text â€” Android, Web, and beyond. Powered by [OpenClaw](https://github.com/openclaw/openclaw).

<p align="center">
  <img src="preview.jpg" alt="OpenClaw Companion â€” Live2D voice assistant" width="300" />
</p>

## âœ¨ Features

- **Push-to-talk voice** â€” hold, speak, release
- **Streaming sentence-by-sentence TTS** â€” hear the first sentence while the AI is still generating
- **Emotion-reactive avatar** â€” 9 animated emotions (happy, sad, surprised, thinking, confused, laughing, neutral, angry, love)
- **Barge-in** â€” interrupt the AI mid-response; partial context is preserved
- **Conversation memory** â€” 10-exchange sliding window, persists across reconnects
- **Smart listen mode** â€” ambient always-on listening with wake word detection
- **Speaker identification** â€” recognizes enrolled voices, prioritizes the owner
- **Vision & file analysis** â€” send images or text files for AI analysis
- **Web search** â€” automatic search integration for factual queries
- **Multiple TTS engines** â€” Edge (cloud), Kokoro (local), XTTS (local + voice cloning)
- **Works over Tailscale / LAN / WAN**
- **Headphone media button & lock screen support**

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        WebSocket         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Voice Server (Node.js)      â”‚
â”‚  Android App    â”‚   audio/text/images      â”‚                              â”‚
â”‚                 â”‚â—„â”€â”€ reply_chunk â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â€¢ Voice input  â”‚â—„â”€â”€ audio_chunk â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â”‚ Speaker ID  â”‚ (Python)    â”‚
â”‚  â€¢ Avatar       â”‚                          â”‚  â”‚ :3201       â”‚             â”‚
â”‚  â€¢ Text chat    â”‚                          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚         â”‚                    â”‚
                                             â”‚         â–¼                    â”‚
                                             â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
                                             â”‚  â”‚ Whisper ASR â”‚ :9000      â”‚
                                             â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
                                             â”‚         â”‚                    â”‚
                                             â”‚         â–¼                    â”‚
                                             â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
                                             â”‚  â”‚ OpenClaw Gateway â”‚       â”‚
                                             â”‚  â”‚ (LLM)            â”‚       â”‚
                                             â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
                                             â”‚         â”‚                    â”‚
                                             â”‚         â–¼                    â”‚
                                             â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
                                             â”‚  â”‚ TTS Engine  â”‚            â”‚
                                             â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
                                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Server (Docker Compose)

```bash
cp .env.example .env          # Edit: set GATEWAY_TOKEN at minimum
docker compose up -d           # CPU mode â€” works everywhere
# docker compose -f docker-compose.yml -f docker-compose.gpu.yml up -d  # GPU mode
```

Get the auth token for the Android app:

```bash
docker compose logs voice-server | grep "Token:"
```

### Android App

**Option A â€” Docker build (no SDK needed):**
```bash
cd android
docker build -t openclaw-companion-apk .
docker run --rm openclaw-companion-apk > openclaw-companion.apk
```

**Option B â€” Android Studio:**
1. Open `android/` in Android Studio
2. Build â†’ Build APK(s)

Install the APK, open Settings, enter your server URL (`ws://YOUR_IP:3200`) and auth token.

## âš™ï¸ Configuration

Copy `.env.example` to `.env` and edit. Key variables:

| Variable | Default | Description |
|----------|---------|-------------|
| `AUTH_TOKEN` | *(random)* | Shared secret for app â†” server auth |
| `GATEWAY_URL` | `http://host.docker.internal:18789/...` | OpenClaw chat completions endpoint |
| `GATEWAY_TOKEN` | *(required)* | OpenClaw gateway bearer token |
| `TTS_ENGINE` | `edge` | TTS engine: `edge`, `kokoro`, or `xtts` |
| `TTS_VOICE` | `es-AR-TomasNeural` | Edge TTS voice name |
| `BOT_NAME` | `jarvis` | Wake word for smart-listen mode |
| `WHISPER_LANG` | `es` | Whisper transcription language |
| `ASR_MODEL` | `large-v3-turbo` | Whisper model size |

See [`.env.example`](.env.example) for the complete reference with descriptions.

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ server/                Bridge server (Node.js + Python)
â”‚   â”œâ”€â”€ index.js           WebSocket server & LLM streaming
â”‚   â”œâ”€â”€ speaker_service.py Speaker identification (resemblyzer)
â”‚   â”œâ”€â”€ Dockerfile         Server container build
â”‚   â””â”€â”€ README.md          Server docs & WebSocket protocol reference
â”œâ”€â”€ android/               Android app (Kotlin)
â”œâ”€â”€ docker-compose.yml     CPU deployment (default)
â”œâ”€â”€ docker-compose.gpu.yml GPU override for NVIDIA
â”œâ”€â”€ .env.example           Configuration template
â””â”€â”€ README.md              This file
```

## ğŸ“– Documentation

- **[Server README](server/README.md)** â€” setup, configuration, full WebSocket protocol reference, troubleshooting
- **[`.env.example`](.env.example)** â€” all environment variables with descriptions

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/my-feature`)
3. Commit your changes
4. Push and open a Pull Request

### Development

```bash
# Run server locally (without Docker)
cd server && npm install
node index.js

# Run Whisper separately
docker run -d -p 9000:9000 -e ASR_MODEL=base onerahmet/openai-whisper-asr-webservice:latest
```

## ğŸ“„ License

[MIT](LICENSE)

## ğŸ”— Links

- [OpenClaw](https://github.com/nichochar/openclaw) â€” the AI gateway this connects to
- [Whisper ASR](https://github.com/ahmetoner/whisper-asr-webservice) â€” speech recognition service
- [Edge TTS](https://github.com/rany2/edge-tts) â€” default text-to-speech engine
