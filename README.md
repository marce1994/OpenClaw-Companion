# ğŸ¾ OpenClaw Companion

Open-source voice assistant app for [OpenClaw](https://github.com/openclaw/openclaw). Talk to your AI assistant via voice or text from your Android phone.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Android App â”‚â—„â”€â”€WSâ”€â”€â–ºâ”‚  Bridge Server   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Whisper STT    â”‚
â”‚              â”‚         â”‚  (Node.js)       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  OpenClaw GW    â”‚
â”‚  â€¢ Voice     â”‚         â”‚                  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Edge TTS       â”‚
â”‚  â€¢ Text      â”‚         â”‚  Streams back    â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â€¢ Playback  â”‚         â”‚  sentence-by-    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  sentence audio  â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Features

- **Push-to-talk voice** â€” hold the button, speak, release to send
- **Text input** â€” type messages for noisy environments
- **SSE streaming with sentence-by-sentence TTS** â€” hear the first sentence while the AI is still generating the rest
- **Emotion detection** â€” avatar reacts to the mood of the response
- **Barge-in** â€” interrupt the AI mid-response by speaking; partial context is preserved
- **Conversation memory** â€” maintains last 10 exchanges for multi-turn context, persists across reconnects
- **Replay last response** â€” tap to hear the last answer again
- **Works over Tailscale / LAN / WAN** â€” connect from anywhere
- **Headphone media button** â€” trigger recording via wired/Bluetooth headset
- **Lock screen support** â€” works with screen off via foreground service

## ğŸ“‹ Prerequisites

| Component | Description |
|-----------|-------------|
| **OpenClaw** | An OpenClaw instance with `chatCompletions` enabled |
| **Whisper ASR** | A Whisper STT container (e.g. [whisper-asr-webservice](https://github.com/ahmetoner/whisper-asr-webservice)) |
| **Docker** | For building and running the server (and optionally the APK) |

## ğŸš€ Quick Start

### 1. Start the server (Docker Compose)

```bash
cp .env.example .env
# Edit .env â€” you MUST set GATEWAY_URL and GATEWAY_TOKEN

# CPU (works everywhere):
docker compose up -d

# GPU (NVIDIA, much faster transcription):
docker compose -f docker-compose.yml -f docker-compose.gpu.yml up -d
```

That's it! The server is now running on port 3200.

### 2. Build the Android APK

**With Docker (no Android SDK needed):**

```bash
cd android
docker build -t openclaw-companion-apk .
docker create --name apk-tmp openclaw-companion-apk
docker cp apk-tmp:/project/app/build/outputs/apk/debug/app-debug.apk ./openclaw-companion.apk
docker rm apk-tmp
```

**With Android Studio:**

1. Open the `android/` directory in Android Studio
2. Sync Gradle
3. Build â†’ Build APK(s)

### 3. Connect

Install the APK, open the app, go to Settings, and enter:
- **Server URL:** `ws://YOUR-SERVER-IP:3200`
- **Auth token:** the `AUTH_TOKEN` from your `.env`

## âš™ï¸ Configuration

All configuration is done via environment variables in `.env`. See [`.env.example`](.env.example) for the full reference.

**Required:**

| Variable | Description |
|----------|-------------|
| `GATEWAY_URL` | OpenClaw chat completions endpoint (e.g. `http://host.docker.internal:18789/v1/chat/completions`) |
| `GATEWAY_TOKEN` | Bearer token for the OpenClaw gateway |
| `AUTH_TOKEN` | Shared secret between the Android app and server |

**Optional (have sensible defaults):**

| Variable | Default | Description |
|----------|---------|-------------|
| `TTS_ENGINE` | `edge` | TTS engine: `edge` (cloud), `kokoro` (local GPU), `xtts` (local GPU) |
| `TTS_VOICE` | `es-AR-TomasNeural` | Edge TTS voice ([list voices](https://gist.github.com/BettyJJ/17cbaa1de96235a7f5773b8571a3ea95)) |
| `ASR_MODEL` | `small` (CPU) / `large-v3-turbo` (GPU) | Whisper model |
| `ASR_LANGUAGE` | `es` | Speech recognition language |
| `BOT_NAME` | `assistant` | Wake word for Smart Listen mode |
| `OWNER_NAME` | `User` | Primary user name for speaker identification |

## ğŸ“¡ WebSocket Protocol

The app communicates with the bridge server over WebSocket (JSON messages). Sessions persist across reconnects.

**Client â†’ Server:**
- `auth` â€” authenticate with token and optional session ID
- `audio` / `text` / `image` / `file` â€” send input for processing
- `ambient_audio` â€” always-listening mode audio
- `barge_in` â€” interrupt AI mid-response (aborts LLM, stops playback)
- `clear_history` â€” clear conversation memory
- `cancel` â€” cancel current generation
- `ping` â€” keep-alive

**Server â†’ Client:**
- `status` â€” state changes (`transcribing` â†’ `thinking` â†’ `speaking` â†’ `idle`)
- `transcript` â€” what Whisper heard
- `reply_chunk` + `audio_chunk` â€” streamed sentence-by-sentence with TTS
- `stream_done` â€” all chunks sent
- `stop_playback` â€” stop audio (sent on barge-in)
- `history_cleared` â€” conversation memory cleared
- `emotion` â€” avatar emotion tag
- `error` â€” error message

See [server/README.md](server/README.md) for the full protocol reference.

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ docker-compose.yml   One-command server setup
â”œâ”€â”€ .env.example         Configuration template
â”œâ”€â”€ server/              Bridge server (Node.js + Python)
â”‚   â”œâ”€â”€ index.js         WebSocket server & TTS
â”‚   â”œâ”€â”€ speaker_service.py  Speaker identification (Resemblyzer)
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ README.md        Server docs & protocol reference
â”œâ”€â”€ android/             Android app (Kotlin)
â”‚   â”œâ”€â”€ app/src/main/    App source code
â”‚   â””â”€â”€ Dockerfile       APK build without Android Studio
â”œâ”€â”€ PLAN.md              Development roadmap
â””â”€â”€ LICENSE              MIT
```

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/my-feature`)
3. Commit your changes
4. Push to the branch and open a Pull Request

## ğŸ“„ License

[MIT](LICENSE)

## ğŸ”— Links

- [OpenClaw](https://github.com/openclaw/openclaw) â€” the AI gateway this app connects to
