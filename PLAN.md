# OpenClaw Companion â€” Development Plan

> Last updated: 2026-02-09

---

## Identity

- **App name**: OpenClaw Companion
- **Package**: `com.openclaw.companion`
- **Bot name**: Configurable by user (default: "Assistant")

---

## MVP Features

### 1. Interaction Modes
- [x] **Push-to-talk** (hold button) â€” default mode, works on screen and headphones
- [ ] **Tap-to-talk + VAD** â€” tap to start, auto-detect end of speech (Silero VAD)
- [ ] **Continuous conversation** â€” call-style loop after each response
- [ ] **Configurable switch** between modes in settings
- [x] **Headphones**: physical button support (hold to record)
- [x] **Text mode** â€” keyboard input for noisy environments

### 2. Audio
- [x] **Streaming TTS** â€” response starts playing before full text is generated
- [ ] **Interruptions** â€” stop audio if user starts speaking
- [ ] **Sound feedback** â€” short tones on record start/stop
- [x] **Vibration** â€” haptic feedback on activation
- [ ] **Latency target** â€” <1s from end of speech to start of response

### 3. UI / Visual Design
- [x] **Dark theme** â€” dark background, clean layout
- [x] **Selectable animated avatars**:
  - ðŸ¾ Cute mascot (blinks, reacts)
  - ðŸ‘ï¸ Intelligent eye (Jarvis-style, futuristic)
  - ðŸ”® Pulsing orb (ChatGPT/Grok-style, minimalist)
- [x] **Animated states** per avatar:
  - Idle â€” gentle breathing / blinking
  - Listening â€” reacts to voice amplitude
  - Thinking â€” processing animation
  - Speaking â€” synced with audio response
  - Error â€” distinct visual indicator
- [x] **Lottie animations** â€” vector-based, lightweight, smooth
- [x] **Portrait lock** â€” fixed vertical orientation
- [x] **Minimal controls** visible: mic, keyboard, close
- [x] **Smooth transitions** between states

### 4. Session & Context
- [x] **Unified session with Telegram** â€” shares conversation context
- [ ] **Multi-turn context** â€” full history in session
- [ ] **Conversation history** â€” searchable past conversations screen
- [ ] **Real-time transcription** â€” optional toggle

### 5. Android Integration
- [ ] **Assist app** â€” register with `VoiceInteractionService`, long-press Home opens app
- [ ] **1x1 Widget** â€” mic button for quick activation
- [x] **Persistent notification** â€” quick access from notification bar
- [x] **Battery exclusion** â€” works with screen locked
- [x] **Wake lock** â€” keeps service active in background

### 6. Settings
- [x] Server URL
- [x] Auth token
- [ ] **Bot name** (customizable, used throughout UI)
- [x] **Avatar selector** (mascot / eye / orb)
- [ ] **Interaction mode** (push-to-talk / tap+VAD / continuous)
- [x] Auto-play responses
- [x] Vibration on/off
- [ ] Show real-time transcription on/off

---

## Technical Architecture

### Audio Pipeline
```
[Mic] â†’ VAD (Silero, on-device) â†’ PCM/WAV â†’ WebSocket â†’ Server
Server: Whisper STT â†’ OpenClaw LLM (SSE) â†’ Edge-TTS â†’ WebSocket
WebSocket â†’ [Speaker] + transcription in UI
```

### Stack
- **Android**: Kotlin, Lottie for animations, OkHttp WebSocket
- **Server**: Node.js, WebSocket bidirectional
- **STT**: Whisper ASR (container)
- **LLM**: OpenClaw gateway (chat/completions with SSE streaming)
- **TTS**: Edge-TTS (server-side, Microsoft neural voices)
- **VAD**: Silero VAD (Android on-device) â€” planned

---

## Implementation Phases

### Phase 1 â€” Foundation (v0.2) âœ… COMPLETE
1. Rename app to OpenClaw Companion
2. Fixed vertical orientation
3. Bot name field in settings
4. Push-to-talk with headphones (hold to record)
5. Improved sound feedback
6. Basic UI redesign (dark background, clean layout)

### Phase 2 â€” Avatars & Animations (v0.3) âœ… COMPLETE
1. Integrate Lottie
2. Implement pulsing orb (first avatar)
3. Animated states (idle/listening/thinking/speaking)
4. Avatar selector in settings (orb, then more)

### Phase 3 â€” VAD & Modes (v0.4) â€” PLANNED
1. Integrate Silero VAD on Android
2. Tap-to-talk mode with end-of-speech detection
3. Mode switch in settings
4. Continuous conversation mode

### Phase 4 â€” Streaming & Interruptions (v0.5) âœ… COMPLETE
1. SSE streaming from OpenClaw gateway
2. Sentence-by-sentence TTS generation
3. Parallel TTS + streaming to client
4. Reduced latency (2-4s improvement)

### Phase 5 â€” Android Integration (v0.6) â€” PLANNED
1. Register as Assist app
2. 1x1 Widget
3. Conversation history

### Phase 6 â€” Additional Avatars (v0.7) âœ… COMPLETE
1. Cute mascot avatar
2. Intelligent eye avatar
3. Custom sound design

### Phase 7 â€” Polish (v0.8) â€” PLANNED
- [ ] Headphones: toggle mode (one click to record, another to send)
- [ ] Polish skin colors
- [ ] Cute avatar: more expression when thinking
- [ ] Cute avatar: more expressive mouth when speaking (synced with audio)
- [ ] Swipe to cancel: adjust sensitivity

### Phase 8 â€” Live2D VTuber (v0.9) â€” PLANNED
- [ ] Integrate Live2D Cubism SDK (free for open source/individuals)
- [ ] Default model included in app
- [ ] Import custom `.moc3` models
- [ ] MotionSync â€” mouth sync with audio
- [ ] Model states: idle (blinking), listening (attentive), thinking, speaking
- [ ] Model selector in settings

---

## Nice-to-have (post-MVP)
- Wake word ("Hey [name]") with Picovoice
- Whisper mode (speak softly â†’ respond softly)
- Brief mode (short responses)
- Quick Settings Tile
- Floating bubble (overlay)
- Share sheet integration
- Multimodal (send photos)
- Additional skins/themes
- Export conversations

---

## Notes
- Unified Telegram session works via `x-openclaw-session-key` header
- Server runs in Docker
- APK builds via Docker (no Android Studio required)
- SSE streaming + sentence chunking + parallel TTS is implemented and working

## Performance Benchmarks (2026-02-09)
- Whisper transcription: ~400ms
- LLM response (via OpenClaw): ~1-3s
- Edge-TTS generation: ~2s for typical response
- With streaming: first audio chunk arrives 2-4s sooner than non-streaming
