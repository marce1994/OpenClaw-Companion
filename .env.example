# ╔══════════════════════════════════════════════════════════════════════════╗
# ║  OpenClaw Companion — Environment Configuration                        ║
# ║  Copy this file to .env and edit with your values                      ║
# ╚══════════════════════════════════════════════════════════════════════════╝

# ─── Required ─────────────────────────────────────────────────────────────

# OpenClaw gateway chat completions endpoint
# Find this in your OpenClaw config (gateway.http.endpoints.chatCompletions)
GATEWAY_URL=http://host.docker.internal:18789/v1/chat/completions

# OpenClaw gateway auth token
# Find this in your OpenClaw config (gateway.auth.token)
GATEWAY_TOKEN=your-gateway-token-here

# ─── Authentication ───────────────────────────────────────────────────────

# Shared secret between the Android app and the server
# Change this to something unique!
AUTH_TOKEN=change-me-to-something-secret

# ─── Speech Recognition ──────────────────────────────────────────────────

# Whisper model for Speaches (faster-whisper CTranslate2)
# Default: Systran/faster-whisper-large-v3-turbo (best speed/quality, ~260ms on RTX 3090)
# Note: Systran model is gated — requires HF_TOKEN below.
# Alternative (ungated, identical weights): deepdml/faster-whisper-large-v3-turbo-ct2
ASR_MODEL=Systran/faster-whisper-large-v3-turbo

# HuggingFace token (required for Systran gated model, optional for deepdml)
# Get yours at https://huggingface.co/settings/tokens (Read access)
HF_TOKEN=

# Whisper model to pass in API requests
WHISPER_MODEL=Systran/faster-whisper-large-v3-turbo

# ─── Text-to-Speech ──────────────────────────────────────────────────────

# TTS engine: edge (default, cloud), kokoro (local GPU), xtts (local GPU)
TTS_ENGINE=edge

# Edge TTS voice (see: edge-tts --list-voices)
# Some good options:
#   es-AR-TomasNeural    (Argentine Spanish, male)
#   es-AR-ElenaNeural    (Argentine Spanish, female)
#   es-MX-JorgeNeural    (Mexican Spanish, male)
#   en-US-GuyNeural      (US English, male)
TTS_VOICE=es-AR-TomasNeural

# Kokoro TTS (only if TTS_ENGINE=kokoro)
# Start with: docker compose --profile kokoro up -d
# ~1GB VRAM, ~400ms latency, no voice cloning
# KOKORO_URL=http://kokoro-tts:8080
# KOKORO_VOICE=em_alex

# XTTS v2 (only if TTS_ENGINE=xtts)
# Start with: docker compose --profile xtts up -d
# ~2.5GB VRAM, ~1s first chunk, supports voice cloning
# WARNING: ~30GB Docker image
# XTTS_URL=http://xtts-server:80

# ─── Voice Assistant ──────────────────────────────────────────────────────

# Bot name (used as wake word in Smart Listen mode)
BOT_NAME=assistant

# Primary user name (for speaker identification)
OWNER_NAME=User

# ─── Networking ───────────────────────────────────────────────────────────

# WebSocket server port (exposed to the Android app)
PORT=3200

# Whisper ASR port (internal, usually leave as default)
WHISPER_PORT=9000
